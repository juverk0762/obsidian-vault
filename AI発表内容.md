# AI活用プレゼン 45 min + QA 10 min

---

## 0. タイムテーブル（全体像）

| セクション                                             | 目安時間     | スライド枚数 |
| ------------------------------------------------- | -------- | ------ |
| **1. オープニング（自己紹介）**                               | 3 min    | 1      |
| **2. AIの進化が加速している、そのロードマップとは**                    | 7 min    | 2–3    |
| **3. デバイスの進化と音声UI時代**                             | 5 min    | 1      |
| **4. これからの勝ち筋：ハードスキル（データ）× ソフトスキル（AI活用習慣）で差別化する** | 7 min    | 2-3    |
| **5. では、どのようなAIを使うべきなのか？（OpenAI / Google）**       | 5 min    | 1–2    |
| **6. クロージング**                                     | 3 min    | 1      |
| _デモ：AIエージェント、音声による文章作成+α（9月までに新機能が出た場合に調整）_       | _15 min_ | _–_    |
| Q&A                                               | 10 min   | –      |

---

## 1. オープニング（自己紹介）

**河野 良平 / LINEヤフー メディアカンパニー所属**

- **現在の業務**
    
    - ヤフーファイナンス「掲示板（UGC）」領域のプロダクトマネージャー
        
    - AIを活用した機能の開発企画などを担当
        
- **ミッション**
    
    -  AI を用いて掲示板利用ユーザの最大化、健全性を高める
        
- **取り組み（例）**
    
    - モデレーション支援：AIが違法なテキスト投稿や画像を判定し自動削除する、AIが精査して違反度が高いものと違反度が低いものは自動処理する
        
    - 掲示板要約：特定の掲示板で現在の状況を要約したものを見られる
        
    - 良い投稿をAIでピックアップ：投資の参考になる情報をAIが判定して、ピックアップしてユーザに届ける
        
- **社内外での発信**
    
    - 社内横断の AI 勉強会に継続登壇（事例共有・ノウハウ展開）
        
    - コーポレートブログでの事例取材・公開（準備中）
        
- **ポジション**
    
    - A**I 実装**の企画やフローを整理して社内で共有
        

## 2. AIの進化が加速している――そのロードマップとは？

**現在地（2025）**

- マルチモーダル & リアルタイム応答が実用域。特定タスクで**人間並み/超**の精度が観測される領域も増加。
    
- “聞く/打つ”中心から、**会話（Voice）× 自動実行（Agent）**へ重心が移動。
    

**今後のマイルストーン（私見）**

1. **2025–27：Gen AI／Agents**
    
    - Q&A から **“秘書/同僚”型エージェント**へ。ワークフロー自動化・モニタリング・要約・リサーチを“丸ごと”任せるケースが増える。
        
2. **2027–29：Narrow AGI（限定汎用）**
    
    - 医療/金融/小売など**業界特化**で、人間レベルの企画→実行→振り返りを**自己改善ループ**で回す。範囲外は不得手、**人の監督**は必要。
        
3. **2030–35：Broad AGI（広域汎用）**
    
    - **複数ドメイン横断**で平均的人レベルの対応。ロボティクス/IoT と接続し、現場オペの一部を肩代わり。**安全性/ガバナンス**が主要テーマ。
        
4. **2035+：ASI（超知能）**
    
    - ここから先は**SFに近い仮説**。研究・規制・倫理の進展次第で大きくブレるため、本プレゼンでは深追いしない。
        

**補足：ロボティクスの位置づけ**

- 2020年代末～2030年代前半にかけて、**接客/倉庫/清掃など現場タスク**で AI ロボが段階的に浸透（プロトタイプ→限定実装→一部常用）。
    

**注意書き（期待値コントロール）**

- 年次は**中央値ベースのレンジ感**。国/企業/規制で前後する。米中の実装速度は相対的に速く、**SFが現実に寄っている領域**が増加中。
    

**スライド化の指示**

- 左から右への**タイムライン矢印**に上記4フェーズを配置。各フェーズに 1 行要約とキーワード（EN）を併記：
    
    - Agents（workflow automation, voice）
        
    - Narrow AGI（domain-specialist, self-improvement）
        
    - Broad AGI（cross-domain, meta-learning, safety）
        
    - ASI（speculative, governance）
        
- 矢印の下に**薄グレーの不確実性バー**（±数年）を入れる。
    
- AIロボティクスについても27年〜30年くらいから本格化することを記載する
    

**3**----------- |

|年度帯|フェーズ|キーワード|早期シナリオ|
|---|---|---|---|
|2025–27|**Gen AI／Agents**|マルチモーダル・Voice|’24–26|
|2027–29|**Narrow AGI**|業界特化・自己改善|’25–26|
|2030–35|**Broad AGI**|クロスドメイン汎用|’28–30|
|2035+|**ASI**|超知能・自己改良|不明/まだSFチックなので割愛|

---

## 3. デバイスの進化と「音声UI」時代

- デバイスは **小さく** なり、**身体に近づく** ほど常時接続になる。
    
- 入力は **TYPE → TOUCH → TALK** へ。身につける段階では“話す”が主流に。
    

**進化の5段階（距離 × 侵襲性）**

1. **机の上（PC）** _TYPE_ … キーボード/マウス。
    
2. **手のひら・ポケット（スマホ）** _TOUCH_ … タップ/スワイプが主。
    
3. **身につける（スマートグラス/イヤホン/リング）** _TALK_ … ハンズフリー音声＋視線・カメラ。**2025–28 に本格普及レンジ**。
    
4. **半侵襲（コンタクト型AR）** … 角膜上のHUD、R&D～限定用途。
    
5. **侵襲（BMI/ナノボット）** … 医療リハビリが先行、一般化は長期スパン。
    

> 用語メモ：
> 
> - **非侵襲**（身につける）：装着のみ。メガネ/イヤホンなど。
>     
> - **半侵襲**：角膜上に装着（例：コンタクト型）。
>     
> - **侵襲**：体内に埋め込む/体内で機能（例：脳-機械インターフェース）。
>     

```
TYPE  →  TOUCH  →  TALK  →  (Semi-/Invasive)
机上        手元         身につける        体内へ
```

**なぜ“音声”が主流になるのか**

- **手がふさがる**状況（施術/移動/現場作業）でも操作できる。
    
- **画面を見ない**前提でも、会話で意思決定が進む（要約・読み上げ・実行）。
    
- LLM が **リアルタイム**で音声を理解/応答（“待ち時間=打鍵”の解消）。
    
- AIロボティクスについても音声での対応が中心になる
    

## 4. データ蓄積 = パーソナルAIを育てる

AIのモデルは時間によって進化していくが、お金さえ払えば活用できるので基本的には平等。ただし、月数十万円〜数百万円するAIみたいなものも出現する可能性があるので、それについては資本の差が出る

皆が平等に高性能モデルを使えるとして、どこで差別化するか？

ハード面とソフト面で差別化する

### 差別化の 2 軸（ハード × ソフト）

- **① ハード＝データ資産で差をつける**
    
    - AIはメモリ機能が高まっているため、AIに対してさまざまな質問をする、議論する、指摘するなどでデータを貯める
        
    - 自社あるいは自分専用のデータの整理や蓄積を開始する
        

### 8 つの素材

1. 経営ドキュメント（事業計画・月次 P/L）
    
2. 日報 & 振り返り（スタッフ日報・30 秒ボイス）
    
3. 施術 & KPI ログ（客単価・在庫）
    
4. 学習メモ（セミナー要点など）
    
5. 顧客の声（口コミ・CS チャット）
    
6. SNS & ブログ（投稿本文・インプレッション）
    
7. AI 会話ログ（人格形成）
    
8. テンプレ & 資料（契約書式など）
    

いつでもAIに学習させられるようにする

- **② ソフト＝活用習慣をつける**
    
    - 毎日AIを使う、できれば同じAI、かつメモリとして蓄積できる機能があるものを使う
        
    - AIに名前をつけたり、愛着が持てるキャラ性をつけるでもOK。単なる質問するツールではなく、パートナーやエージェントとして活用する
        
    - 音声対話に慣れておく、人で仕事中にブツブツ話すのは最初は結構やりにくい、今から声を発する練習をする
        
    - （個人的な話）10年前にメガネ型デバイスがくると思ったので、そこからずっと練習のため伊達でメガネをつけはじめた。本当に目も悪くなったので、いつメガネデバイスが来てもいいように今も基本的につけている
        
    - モデルは進化＝**性能は平等化**の方向。**違いはあなたのデータと使い込み**による。今から投資と思って、少しずつAIを使って慣れておきたいです
        

---

## 5. どの AI を使う?

では、どの AI を使うべきか?

AIサービスが乱立しており、どれ使えばいいかわからない

＜画像化したい＞

アプリケーション（AIサービスのカオスマップ）

↑この部分が大量に開発されてる、ここを追いかけるのは沼。良いと思うものを少数使う

===============

言語モデル

↑ここをおさえる、言語モデル側もいずれはサービスを提供するので、それを活用するで良い。言語モデルのメモリに情報を蓄積するがベスト

大規模言語モデルは今で言う、OS（windows/mac、iOS/Android）みたいな存在

現状のITサービスは「OSの標準化」をとったサービスが覇権となり、その時代のリーダーとなるという構造がある

原則的には大規模言語モデルを提供しているサービスのAIに投資しておくのが良い

大規模言語モデルを提供している主だったプレイヤーは「OpenAI（ChatGPT）」「Google（Gemini）」「Anthropic（Claude）」、モデル性能やAIサービスの機能でいえば、OpenAIが頭一つぬけていて、Googleが追随する構図になっている

ただし、GoogleはAndroidというOSを持ち、Google検索やYouTube、マップ、Chrome、Gmailそのほか世界で10億人以上が使うサービスを多数展開している、デバイス（Pixel）もあるため、自前のデータ量やユーザとの接点という観点では圧倒的。店舗経営という観点だとGoogleのほうが適している可能性がある

一方、OpenAIもブラウザやSNS、AIデバイスを開発している状況にあり、今後ユーザがChatGPTを起動するための「起点」をおさえようとしている。なお、ソフトバンクグループはOpenAIに全betしている

この 2 社に絞って “対話 & データ蓄積” を積むのが筋。個人的にはメインはOpenAI、一部機能（notebookLMなど）はGoogleを活用している。今後、スプレッドシートのAI活用がよりしやすくなった場合はGoogleの比重をあげる可能性がある

|項目|**OpenAI**|**Google**|
|---|---|---|
|強み|生成品質・速度|デバイス & 検索エコシステム|
|リーチ|ChatGPT 週 4 億 MAU|Android 35 億台|
|戦略|API + Voice + ioβ|Gemini in Workspace / Search|

---

## 6. CTA & クロージング

- **ここまでのまとめを記載**
    

---

> **Next (自分向けメモ)**
> 
> - デモ詳細 & 音声 UI スライドを後日ブラッシュアップ
>     
> - 追加リマインドが必要ならお知らせください
>